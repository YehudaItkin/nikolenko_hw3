{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "ku3EPHCh2Gan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoRpFJx_pBWv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
        "# !tar -xvf facades.tar.gz"
      ],
      "metadata": {
        "id": "ZjDYv_wHq2A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-i44PwHs4yv",
        "outputId": "2badb6b3-455d-442d-e2d7-eaae4af585e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import os, sys\n",
        "import argparse"
      ],
      "metadata": {
        "id": "rD8-G82dyX8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"/content\"))\n",
        "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
        "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"/content/code\"))\n",
        "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
        "sys.path.append(\".\")\n",
        "\n",
        "from datasets import DatasetFromFolder\n",
        "from model import Generator, Discriminator\n",
        "import utils"
      ],
      "metadata": {
        "id": "aFJr5WqRuvZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = argparse.Namespace()\n",
        "params.dataset = \"facades\"\n",
        "params.direction = 'BtoA'\n",
        "params.batch_size = 1\n",
        "params.ngf = 64\n",
        "params.ndf = 64\n",
        "params.input_size = 256\n",
        "params.resize_scale =286\n",
        "params.crop_size = 256\n",
        "params.fliplr = True\n",
        "params.num_epochs = 20\n",
        "params.lrG = 0.0002\n",
        "params.lrD = 0.0002\n",
        "params.lamb = 100.0\n",
        "params.beta1 = 0.5\n",
        "params.beta2 = 0.999\n",
        "params.data_dir = \"/content/facades\""
      ],
      "metadata": {
        "id": "NwqtuD5ayGqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize(params.input_size),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]\n",
        "                               )\n",
        "# Train data\n",
        "train_data = DatasetFromFolder(params.data_dir, subfolder='train', direction=params.direction, transform=transform,\n",
        "                               resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                                batch_size=params.batch_size,\n",
        "                                                shuffle=True)\n",
        "\n",
        "# Test data\n",
        "test_data = DatasetFromFolder(params.data_dir, subfolder='test', direction=params.direction, transform=transform)\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                               batch_size=params.batch_size,\n",
        "                                               shuffle=False)\n",
        "test_input, test_target = test_data_loader.__iter__().__next__()"
      ],
      "metadata": {
        "id": "ooPfjppAyV-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator(3, params.ngf, 3)\n",
        "D = Discriminator(6, params.ndf, 1)\n",
        "G.cuda()\n",
        "D.cuda()\n",
        "G.normal_weight_init(mean=0.0, std=0.02)\n",
        "D.normal_weight_init(mean=0.0, std=0.02)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBSBfRxB0rBv",
        "outputId": "b5c8cdc9-5e14-4a01-8d6e-99547383fa65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/model.py:102: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  torch.nn.init.normal(m.conv.weight, mean, std)\n",
            "/content/model.py:104: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  torch.nn.init.normal(m.deconv.weight, mean, std)\n",
            "/content/model.py:131: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  torch.nn.init.normal(m.conv.weight, mean, std)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "BCE_loss = torch.nn.BCELoss().cuda()\n",
        "L1_loss = torch.nn.L1Loss().cuda()\n",
        "\n",
        "# Optimizers\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr=params.lrG, betas=(params.beta1, params.beta2))\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wfyfYH1T05I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training GAN\n",
        "D_avg_losses = []\n",
        "G_avg_losses = []\n",
        "\n",
        "step = 0\n",
        "for epoch in range(params.num_epochs):\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "\n",
        "    # training\n",
        "    for i, (input, target) in enumerate(train_data_loader):\n",
        "\n",
        "        # input & target image data\n",
        "        x_ = input.cuda()\n",
        "        y_ = target.cuda()\n",
        "\n",
        "        # Train discriminator with real data\n",
        "        D_real_decision = D(x_, y_).squeeze()\n",
        "        real_ = torch.ones(D_real_decision.size()).cuda()\n",
        "        D_real_loss = BCE_loss(D_real_decision, real_)\n",
        "\n",
        "        # Train discriminator with fake data\n",
        "        gen_image = G(x_)\n",
        "        D_fake_decision = D(x_, gen_image).squeeze()\n",
        "        fake_ = torch.zeros(D_fake_decision.size()).cuda()\n",
        "        D_fake_loss = BCE_loss(D_fake_decision, fake_)\n",
        "\n",
        "        # Back propagation\n",
        "        D_loss = (D_real_loss + D_fake_loss) * 0.5\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Train generator\n",
        "        gen_image = G(x_)\n",
        "        D_fake_decision = D(x_, gen_image).squeeze()\n",
        "        G_fake_loss = BCE_loss(D_fake_decision, real_)\n",
        "\n",
        "        # L1 loss\n",
        "        l1_loss = params.lamb * L1_loss(gen_image, y_)\n",
        "\n",
        "        # Back propagation\n",
        "        G_loss = G_fake_loss + l1_loss\n",
        "        G.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        # loss values\n",
        "        D_losses.append(D_loss.item())\n",
        "        G_losses.append(G_loss.item())\n",
        "\n",
        "        print('Epoch [%d/%d], Step [%d/%d], D_loss: %.4f, G_loss: %.4f'\n",
        "              % (epoch+1, params.num_epochs, i+1, len(train_data_loader), D_loss.item(), G_loss.item()))\n",
        "        \n",
        "        step += 1\n",
        "\n",
        "    D_avg_loss = torch.mean(torch.FloatTensor(D_losses))\n",
        "    G_avg_loss = torch.mean(torch.FloatTensor(G_losses))\n",
        "\n",
        "    # avg loss values for plot\n",
        "    D_avg_losses.append(D_avg_loss)\n",
        "    G_avg_losses.append(G_avg_loss)\n",
        "\n",
        "    # Show result for test image\n",
        "    gen_image = G(test_input.cuda())\n",
        "    gen_image = gen_image.cpu().data\n",
        "    utils.plot_test_result(test_input, test_target, gen_image, epoch, save=True)\n",
        "\n",
        "# Plot average losses\n",
        "utils.plot_loss(D_avg_losses, G_avg_losses, params.num_epochs, save=True)\n"
      ],
      "metadata": {
        "id": "py0hkvv4rBJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.make_gif(params.dataset, params.num_epochs, save_dir=\"./results/\")"
      ],
      "metadata": {
        "id": "4LAZ7ibJrV_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r all.zip *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPVrXSuM8QNy",
        "outputId": "a1aa692f-d4a2-4368-be11-23dcc2961bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: code/ (stored 0%)\n",
            "  adding: code/__init__.py (stored 0%)\n",
            "  adding: code/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: code/__pycache__/ (stored 0%)\n",
            "  adding: code/__pycache__/__init__.cpython-38.pyc (deflated 30%)\n",
            "  adding: datasets.py (deflated 70%)\n",
            "  adding: __init__.py (stored 0%)\n",
            "  adding: model.py (deflated 80%)\n",
            "  adding: __pycache__/ (stored 0%)\n",
            "  adding: __pycache__/utils.cpython-38.pyc (deflated 39%)\n",
            "  adding: __pycache__/__init__.cpython-38.pyc (deflated 30%)\n",
            "  adding: __pycache__/model.cpython-38.pyc (deflated 57%)\n",
            "  adding: __pycache__/datasets.cpython-38.pyc (deflated 44%)\n",
            "  adding: results/ (stored 0%)\n",
            "  adding: results/Result_epoch_5.png (deflated 2%)\n",
            "  adding: results/Result_epoch_3.png (deflated 3%)\n",
            "  adding: results/Result_epoch_7.png (deflated 2%)\n",
            "  adding: results/Result_epoch_12.png (deflated 2%)\n",
            "  adding: results/Result_epoch_6.png (deflated 2%)\n",
            "  adding: results/Result_epoch_11.png (deflated 2%)\n",
            "  adding: results/facades_pix2pix_epochs_20.gif (deflated 8%)\n",
            "  adding: results/Result_epoch_18.png (deflated 3%)\n",
            "  adding: results/Result_epoch_20.png (deflated 2%)\n",
            "  adding: results/Loss_values_epoch_20.png (deflated 10%)\n",
            "  adding: results/Result_epoch_16.png (deflated 2%)\n",
            "  adding: results/Result_epoch_4.png (deflated 2%)\n",
            "  adding: results/Result_epoch_8.png (deflated 2%)\n",
            "  adding: results/Result_epoch_15.png (deflated 2%)\n",
            "  adding: results/Result_epoch_13.png (deflated 3%)\n",
            "  adding: results/Result_epoch_2.png (deflated 2%)\n",
            "  adding: results/Result_epoch_1.png (deflated 2%)\n",
            "  adding: results/Result_epoch_14.png (deflated 3%)\n",
            "  adding: results/Result_epoch_17.png (deflated 2%)\n",
            "  adding: results/Result_epoch_10.png (deflated 2%)\n",
            "  adding: results/Result_epoch_19.png (deflated 3%)\n",
            "  adding: results/Result_epoch_9.png (deflated 2%)\n",
            "  adding: sample_data/ (stored 0%)\n",
            "  adding: sample_data/anscombe.json (deflated 83%)\n",
            "  adding: sample_data/README.md (deflated 42%)\n",
            "  adding: sample_data/california_housing_train.csv (deflated 79%)\n",
            "  adding: sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: utils.py (deflated 63%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fguFtlF599vM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}