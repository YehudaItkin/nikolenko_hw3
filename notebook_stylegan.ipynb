{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"/content\"))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"/content/code\"))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from models_style import Generator\n",
    "from models_style import Discriminator\n",
    "from utils import ReplayBuffer\n",
    "from utils import LambdaLR\n",
    "from utils import Logger\n",
    "from utils import weights_init_normal\n",
    "from datasets import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = argparse.Namespace()\n",
    "params.dataset = \"facades\"\n",
    "params.num_epochs = 150\n",
    "params.batch_size = 1\n",
    "params.lr = 0.0002\n",
    "params.decay_epoch = 100\n",
    "params.input_size = 256\n",
    "params.resize_scale =286\n",
    "params.crop_size = 256\n",
    "params.input_nc = 3\n",
    "params.output_nc = 3\n",
    "params.dataroot = os.path.join(os.path.abspath('.'), 'datasets/horse2zebra/')\n",
    "params.device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "netG_A2B = Generator(params.input_nc, params.output_nc).to(params.device)\n",
    "netG_B2A = Generator(params.output_nc, params.input_nc).to(params.device)\n",
    "netD_A = Discriminator(params.input_nc).to(params.device)\n",
    "netD_B = Discriminator(params.output_nc).to(params.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "netG_A2B = netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A = netG_B2A.apply(weights_init_normal)\n",
    "netD_A = netD_A.apply(weights_init_normal)\n",
    "netD_B = netD_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                                lr=params.lr, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=params.lr, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=params.lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr_sched_params = LambdaLR(params.num_epochs, 0, params.decay_epoch).step\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=deepcopy(lr_sched_params))\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=deepcopy(lr_sched_params))\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=deepcopy(lr_sched_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "input_A = torch.Tensor(params.batch_size, params.input_nc, params.crop_size, params.crop_size)\n",
    "input_B = torch.Tensor(params.batch_size, params.output_nc, params.crop_size, params.crop_size)\n",
    "target_real =torch.tensor(params.batch_size, requires_grad=False, dtype=torch.float).fill_(1.0).to(params.device)\n",
    "target_fake = torch.tensor(params.batch_size, requires_grad=False, dtype=torch.float).fill_(0.0).to(params.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transforms_ = [ transforms.Resize(int(params.resize_scale), Image.BICUBIC),\n",
    "                transforms.RandomCrop(params.crop_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(params.dataroot, transforms_=transforms_, unaligned=True),\n",
    "                        batch_size=params.batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(params.num_epochs, len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "###################################\n",
    "\n",
    "###### Training ######\n",
    "for epoch in range(0, params.num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Set model input\n",
    "        real_A = batch['A'].to(params.device, torch.float)\n",
    "        real_B = batch['B'].to(params.device, torch.float)\n",
    "\n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = netG_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        pred_fake = netD_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake = netD_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = netG_B2A(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator A ######\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "        pred_fake = netD_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator B ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        ###################################\n",
    "\n",
    "        # Progress report (http://localhost:8097)\n",
    "        logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B), 'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
    "                    'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)},\n",
    "                    images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "    # Save models checkpoints\n",
    "    torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')\n",
    "    torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')\n",
    "    torch.save(netD_A.state_dict(), 'output/netD_A.pth')\n",
    "    torch.save(netD_B.state_dict(), 'output/netD_B.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Поскольку тренировка занимает довольно много времени, я тренировал отдельно. Логи и результаты в директории results_cycle_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "netG_A2B = Generator(params.input_nc, params.output_nc)\n",
    "netG_B2A = Generator(params.output_nc, params.input_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (model): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG_A2B.load_state_dict(torch.load('output/netG_A2B.pth'))\n",
    "netG_B2A.load_state_dict(torch.load('output/netG_B2A.pth'))\n",
    "\n",
    "# Set model's test mode\n",
    "netG_A2B.eval()\n",
    "netG_B2A.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B = netG_A2B.to(params.device)\n",
    "netG_B2A = netG_B2A.to(params.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [ transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(params.dataroot, transforms_=transforms_, mode='test'), \n",
    "                        batch_size=params.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5491/1801963695.py\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;31m# Save image files\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m     \u001B[0msave_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfake_A\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'output/A/%04d.png'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m     \u001B[0msave_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfake_B\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'output/B/%04d.png'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'save_image' is not defined"
     ]
    }
   ],
   "source": [
    "# Create output dirs if they don't exist\n",
    "os.makedirs('output/A', exist_ok=True)\n",
    "os.makedirs('output/B', exist_ok=True)\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    # Set model input\n",
    "    real_A = batch['A'].to(params.device, torch.float)\n",
    "    real_B = batch['B'].to(params.device, torch.float)\n",
    "\n",
    "\n",
    "    # Generate output\n",
    "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "    save_image(fake_A, 'output/A/%04d.png' % (i+1))\n",
    "    save_image(fake_B, 'output/B/%04d.png' % (i+1))\n",
    "\n",
    "    sys.stdout.write('\\rGenerated images %04d of %04d' % (i+1, len(dataloader)))\n",
    "\n",
    "sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
